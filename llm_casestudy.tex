%
% File consilr2024.tex
%
% Contact: petru.rebeja@gmail.com
%% Based on the style files for COLING-2020, which were, in turn,
%% Based on the style files for COLING-2018, which were, in turn,
%% Based on the style files for COLING-2016, which were, in turn,
%% Based on the style files for COLING-2014, which were, in turn,
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn,
%% based on the style files for ACL-2010, which were, in turn,
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{consilr2024}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{authblk}
\usepackage{hyperref}
\usepackage{etoolbox}
\usepackage{graphicx}
\usepackage{subcaption}

\renewcommand*{\Authand}{, }
\renewcommand*{\Authands}{, AND }
\renewcommand*{\Affilfont}{\itshape\mdseries}
\setlength{\affilsep}{2em}   % set the space between author and affiliation

\newcommand{\keyword}[1]{
\hspace{0.2cm}%
\fontsize{10}{12}\selectfont%
\textbf{Keywords: } %
}


%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{\textbf{A Cross-Lingual Analysis of Bias in Large Language Models Using Romanian History}}
\author[1]{Adrian Marius Dumitran}
\author[2]{RÄƒzvan Cosmin Cristia}
\author[3]{Matei-Iulian Cocu}
\affil[1]{University of Bucharest, Softbinator
\break
\texttt{marius.dumitran@unibuc.ro}}
\affil[2]{University of Bucharest
 \break
\texttt{cristiarazvan@gmail.com}}
\affil[3]{University of Bucharest
 \break
\texttt{cocu.matei24@yahoo.com}}
\date{}

\begin{document}
\maketitle
\begin{abstract}
In this case study, we select a set of controversial Romanian historical questions and ask multiple Large Language Models to answer them across languages and contexts, in order to assess their biases. Besides being a study mainly performed for educational purposes, the motivation also lies in the recognition that history is often presented through altered perspectives, primarily influenced by the culture and ideals of a state, even through large language models. Since they are often trained on certain data sets that may present certain ambiguities, the lack of neutrality is subsequently instilled in users. The research process was carried out in three stages, to confirm the idea that the type of response expected can influence, to a certain extent, the response itself; after providing an affirmative answer to some given question, an LLM could shift its way of thinking after being asked the same question again, but being told to respond with a numerical value of a scale. Our research brings to light the predisposition of models to such inconsistencies, within a specific contextualization of the language for the question asked. 
\end{abstract}

\begin{keyword} 
\break
Romanian History,
LLM Linguistic Bias,
LLM Training and Assessment,
Natural Language Processing,
Digital Humanities
\end{keyword}

\section{Introduction}
\label{intro}
Reasoning - the process of drawing conclusions to facilitate problem-solving and decision-making \cite{leighton2003}; a significant number of studies indicate the fact that reasoning has become a prominent feature of LLMs (), but along with this quality comes a certain bias towards some ideologies of certain domains.
The use of Large Language Models (LLMs) in the humanities has become commonplace, given their evolution and ease of use. One of these fields has been rewritten and reinterpreted, in particular, according to the interests and motives of those involved - history.


% % The following footnote without marker is needed for the camera-ready
% % version of the paper.
% % Comment out the instructions (first text) and uncomment the 8 lines
% % under "final paper" for your variant of English.

% \blfootnote{
    
%    \hspace{-0.65cm}  % space normally used by the marker
%    Place licence statement here for the camera-ready version. See
%    Section~\ref{licence} of the instructions for preparing a
%    manuscript.
    
%     % final paper: en-uk version
    
%     \hspace{-0.65cm}  % space normally used by the marker
%     This work is licensed under a Creative Commons
%     Attribution 4.0 International Licence.
%     Licence details:
%     \url{http://creativecommons.org/licenses/by/4.0/}.
    
%     % final paper: en-us version
    
%     \hspace{-0.65cm}  % space normally used by the marker
%     This work is licensed under a Creative Commons
%     Attribution 4.0 International License.
%     License details:
%     \url{http://creativecommons.org/licenses/by/4.0/}.
% }

\section{Methodology}
The methodology for this study was structured into several key stages,
(each designed to ensure a comprehensive analysis of the biases present in Large Language Models (LLMs) when addressing controversial Romanian historical questions.)
\begin{enumerate}
    \item In the initial stage, a set of (15 intrebari, menite sa aduca la lumina biasul)
    \item In the second stage, 
    \begin{enumerate} % cele 3 stagii, da/nu, 1-10 fixat si llm-asa-judge
        \item 
    \end{enumerate}
    \item The third stage
\end{enumerate}


\subsection{LLM Selection}
For our experiments, we chose

\subsection{Questioning Process}

\subsubsection{Prompt}
The following prompt template was used

\subsubsection{Question Selection}



\section{Answer Comparison}



\section{Conclusions}

% include your own bib file like this:
% \bibliographystyle{consilr}
% \bibliography{consilr2024}

\begin{thebibliography}{}

\bibitem[\protect\citename{nume}an]{id}
nume complet
\newblock an-ref
\newblock {\em paper}%, volume~1. optional volum
\newblock editura, etc.

\bibitem[\protect\citename{Leighton} 2003]{leighton2003}
{Defining and describing reasoning: Reasoning as mediator}.
\newblock 2003
\newblock {\em The nature of reasoning}, pages 1-11.


\bibitem[\protect\citename{{}}]{}
{}.
\newblock 
\newblock {\em }, .


\bibitem[\protect\citename{{}}]{}
{}.
\newblock 
\newblock {\em }, .


\bibitem[\protect\citename{{American Psychological Association}}1983]{APA:83}
{American Psychological Association}.
\newblock 1983.
\newblock {\em Publications Manual}.
\newblock American Psychological Association, Washington, DC.

\bibitem[\protect\citename{Chandra \bgroup et al.\egroup }1981]{Chandra:81}
Ashok~K. Chandra, Dexter~C. Kozen, and Larry~J. Stockmeyer.
\newblock 1981.
\newblock Alternation.
\newblock {\em Journal of the Association for Computing Machinery},
 28(1):114--133.

\bibitem[\protect\citename{Gusfield}1997]{Gusfield:97}
Dan Gusfield.
\newblock 1997.
\newblock {\em Algorithms on Strings, Trees and Sequences}.
\newblock Cambridge University Press, Cambridge, UK.

\bibitem[\protect\citename{Rasooli and Tetreault}2015]{rasooli-tetrault-2015}
Mohammad~Sadegh Rasooli and Joel~R. Tetreault. 2015.
\newblock {Yara parser: {A} fast and accurate dependency parser}.
\newblock \emph{Computing Research Repository}, arXiv:1503.06733.
\newblock Version 2.

\bibitem[\protect\citename{Borschinger and Johnson}2011]{borsch2011}
Benjamin Borschinger and Mark Johnson. 2011.
\newblock A particle filter algorithm for {B}ayesian wordsegmentation.
\newblock In \emph{Proceedings of the Australasian Language Technology Association Workshop 2011}, pages 10--18, Canberra, Australia.

\end{thebibliography}

\end{document}
