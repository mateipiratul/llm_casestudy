@book{leighton2003,
    author={Jacqueline P. Leighton},
    title={Defining and describing reasoning: Reasoning as mediator},
    year={2003},
    booktitle={The Nature of Reasoning},
    publisher={Cambridge University Press},
    pages={1--11} 
}

@misc{chandra2025,
    author={Dharani Chandra},
    title={Applications of Large Language Model Reasoning in Feature Generation}, 
    year={2025},
    eprint={2503.11989},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2503.11989}, 
}

@article{cichocka2020,
    title = {Nationalism as collective narcissism},
    journal = {Current Opinion in Behavioral Sciences},
    volume = {34},
    pages = {69-74},
    year = {2020},
    note = {Political Ideologies},
    issn = {2352-1546},
    doi = {https://doi.org/10.1016/j.cobeha.2019.12.013},
    url = {https://www.sciencedirect.com/science/article/pii/S2352154619301445},
    author = {Aleksandra Cichocka and Aleksandra Cislak},
    abstract = {Traditional conceptualisations of nationalism focus on the need for intergroup domination. We argue that current politics are rather driven by the need for recognition of the greatness of one’s nation. In psychological literature, the need for the nation’s appreciation is captured by the concept of collective narcissism—a belief in in-group greatness contingent on external recognition. We demonstrate that collective narcissism is associated with support for national populist parties and policies. We also review the empirical evidence for the intergroup and intragroup concomitants of collective narcissism. We demonstrate that collective narcissism benefits neither out-group nor in-group members. Instead, it helps manage psychological needs of the individual. We conclude that collective narcissism might undermine social cohesion both within and between groups.}
}

@misc{guo2024,
    title={Bias in Large Language Models: Origin, Evaluation, and Mitigation}, 
    author={Yufei Guo and Muzhe Guo and Juntao Su and Zhou Yang and Mengqiu Zhu and Hongfei Li and Mengyang Qiu and Shuo Shuo Liu},
    year={2024},
    eprint={2411.10915},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2411.10915}, 
}

@misc{lutz2025,
    title={The Prompt Makes the Person(a): A Systematic Evaluation of Sociodemographic Persona Prompting for Large Language Models}, 
    author={Marlene Lutz and Indira Sen and Georg Ahnert and Elisa Rogers and Markus Strohmaier},
    year={2025},
    eprint={2507.16076},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2507.16076}, 
}

@article{tao2024,
    author = {Tao, Yan and Viberg, Olga and Baker, Ryan S and Kizilcec, René F},
    title = {Cultural bias and cultural alignment of large language models},
    journal = {PNAS Nexus},
    volume = {3},
    number = {9},
    pages = {pgae346},
    year = {2024},
    month = {09},
    abstract = {Culture fundamentally shapes people’s reasoning, behavior, and communication. As people increasingly use generative artificial intelligence (AI) to expedite and automate personal and professional tasks, cultural values embedded in AI models may bias people’s authentic expression and contribute to the dominance of certain cultures. We conduct a disaggregated evaluation of cultural bias for five widely used large language models (OpenAI’s GPT-4o/4-turbo/4/3.5-turbo/3) by comparing the models’ responses to nationally representative survey data. All models exhibit cultural values resembling English-speaking and Protestant European countries. We test cultural prompting as a control strategy to increase cultural alignment for each country/territory. For later models (GPT-4, 4-turbo, 4o), this improves the cultural alignment of the models’ output for 71–81\% of countries and territories. We suggest using cultural prompting and ongoing evaluation to reduce cultural bias in the output of generative AI.},
    issn = {2752-6542},
    doi = {10.1093/pnasnexus/pgae346},
    url = {https://doi.org/10.1093/pnasnexus/pgae346},
    eprint = {https://academic.oup.com/pnasnexus/article-pdf/3/9/pgae346/59151559/pgae346.pdf},
}

@article{petrescu,
    author = {Cristina Petrescu},
    title = {Who Was the First in Transylvania? On the Origins of the Romanian-Hungarian Controversy Over Minority Rights.},
    url = {https://doi.org/10.1177/0888325403017003006},
    year = {2003},
    journal = {Studia Politica. Romanian Political Science Review},
}

@article{oyserman2008,
  author  = {Oyserman, D. and Lee, S. W.},
  title   = {{Does culture influence what and how we think? Effects of priming individualism and collectivism}},
  journal = {Psychological Bulletin},
  year    = {2008},
  volume  = {134},
  number  = {2},
  pages   = {311--342},
  doi     = {10.1037/0033-2909.134.2.311}
}

@book{hofstede2001,
  author    = {Hofstede, Geert},
  title     = {{Culture's Consequences: Comparing Values, Behaviors, Institutions, and Organizations Across Nations}},
  year      = {2001},
  publisher = {Sage},
  address   = {Thousand Oaks, CA},
  edition   = {2}
}

@article{kumar2024,
  title = {Investigating Implicit Bias in Large Language Models: A Large-Scale Study of Over 50 LLMs},
  author = {Kumar, Divyanshu and Jain, Umang and Agarwal, Sahil and Harshangi, Prashanth},
  journal = {arXiv preprint arXiv:2410.12864},
  year = {2024},
  url = {https://arxiv.org/abs/2410.12864}
}

@inproceedings{weissburg2025,
  title = {LLMs are Biased Teachers: Evaluating LLM Bias in Personalized Education},
  author = {Weissburg, Iain and Anand, Sathvika and Levy, Sharon and Jeong, Haewon},
  booktitle = {Findings of the Association for Computational Linguistics: NAACL 2025},
  pages = {5650--5698},
  year = {2025},
  address = {Albuquerque, New Mexico},
  publisher = {Association for Computational Linguistics},
  doi = {10.18653/v1/2025.findings-naacl.314}
}

@article{sun2025,
  title = {Large Language Models Are Overconfident and Amplify Human Bias},
  author = {Sun, Fengfei and Li, Ningke and Wang, Kailong and Goette, Lorenz},
  journal = {arXiv preprint arXiv:2505.02151},
  year = {2025},
  note = {https://arxiv.org/abs/2505.02151}
}

@article{bhatia2024,
  title   = {Evaluating Dialect Fairness and Robustness of Large Language Models},
  author  = {Bhatia, Gagan and Tang, MingZe and Mahanta, Cristina and Kazi, Madiha and Zhao, Wei},
  journal = {arXiv preprint},
  eprint  = {2410.11005},
  year    = {2024},
  url     = {https://arxiv.org/abs/2410.11005}
}

@misc{zhao2025,
  title={A Survey of Large Language Models}, 
  author={Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
  year={2025},
  eprint={2303.18223},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2303.18223}, 
}

@inproceedings{hauser2024,
  title     = {Large Language Models' Expert-level Global History Knowledge Benchmark (HiST-LLM)},
  author    = {Hauser, Jakob and Kondor, Daniel and Reddish, Jenny and Benam, Majid and Cioni, Enrico and Villa, Federica and Bennett, James S. and Hoyer, Daniel and Francois, Pieter and Turchin, Peter and del Rio-Chanona, R. Maria},
  booktitle = {Advances in Neural Information Processing Systems 37 (Datasets and Benchmarks Track)},
  year      = {2024},
  publisher = {NeurIPS}
}

@misc{deepseekai2025,
  title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
  author={DeepSeek-AI},
  year={2025},
  eprint={2501.12948},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2501.12948}, 
}

@book{coman2013,
  title={Putere și teritoriu},
  author={Coman, Marian},
  year={2013},
  publisher={MintRight Inc}
}

@misc{zheng2023,
  author       = {Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
  title        = {{Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}},
  year         = {2023},
  note         = {arXiv:2306.05685},
  eprint       = {2306.05685},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{li2025,
      title={Exploring the Impact of Temperature on Large Language Models:Hot or Cold?}, 
      author={Lujun Li and Lama Sleem and Niccolo' Gentile and Geoffrey Nichil and Radu State},
      year={2025},
      eprint={2506.07295},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2506.07295}, 
}

@misc{walker2024,
      title={Identifying the sources of ideological bias in GPT models through linguistic variation in output}, 
      author={Christina Walker and Joan C. Timoneda},
      year={2024},
      eprint={2409.06043},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.06043}, 
}

@article{gulias2016,
author = {Gulyás, László and Csüllög, Gábor},
year = {2016},
month = {01},
pages = {129-138.},
title = {The history of formation of the Romanian state – from Middle Ages to the proclamation of the Romanian Kingdom},
volume = {2},
journal = {Prague Papers ont he history of international relations. (ISSN: 2336-7105) 2016/2. 129-138. pp}
}



@inproceedings{jakesch2023, series={CHI ’23},
   title={Co-Writing with Opinionated Language Models Affects Users’ Views},
   url={http://dx.doi.org/10.1145/3544548.3581196},
   DOI={10.1145/3544548.3581196},
   booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
   publisher={ACM},
   author={Jakesch, Maurice and Bhat, Advait and Buschek, Daniel and Zalmanson, Lior and Naaman, Mor},
   year={2023},
   month=apr, pages={1–15},
   collection={CHI ’23}
}

@article{bai2024,
  title = {Measuring Implicit Bias in Explicitly Unbiased Large Language Models},
  author = {Bai, Xuechunzi and Wang, Angelina and Sucholutsky, Ilia and Griffiths, Thomas L.},
  journal = {arXiv preprint arXiv:2402.04105},
  year = {2024},
  note = {https://arxiv.org/abs/2402.04105}
}

@article{exaone35,
  title={EXAONE 3.5: Series of Large Language Models for Real-world Use Cases},
  author={LG AI Research},
  journal={arXiv preprint arXiv:https://arxiv.org/abs/2412.04862},
  year={2024}
}